{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: [Automatic model selection: H2O AutoML](https://medium.com/@mohtedibf/automatic-model-selection-h2o-automl-79b3b4696f58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_144\"; Java(TM) SE Runtime Environment (build 1.8.0_144-b01); Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n",
      "  Starting server from /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/g5/df85rhb10jb9qpw1wdlh0t_m0000gn/T/tmp8varhkzn\n",
      "  JVM stdout: /var/folders/g5/df85rhb10jb9qpw1wdlh0t_m0000gn/T/tmp8varhkzn/h2o_hugo_started_from_python.out\n",
      "  JVM stderr: /var/folders/g5/df85rhb10jb9qpw1wdlh0t_m0000gn/T/tmp8varhkzn/h2o_hugo_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>03 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.16.0.4</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>6 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_hugo_va0v61</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.778 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         03 secs\n",
       "H2O cluster version:        3.16.0.4\n",
       "H2O cluster version age:    6 days\n",
       "H2O cluster name:           H2O_from_python_hugo_va0v61\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.778 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.2 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model selection and tuning\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "htrain = h2o.H2OFrame(train)\n",
    "htest = h2o.H2OFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = htrain.columns\n",
    "y = 'Survived'\n",
    "x.remove(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This line is added in the case of classification\n",
    "htrain[y] = htrain[y].asfactor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the AutoML function, we just specify how long we want to train for and we're set. For this example, we will train for 120 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                             </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_grid_0_AutoML_20180122_155408_model_1            </td><td style=\"text-align: right;\">0.928836</td><td style=\"text-align: right;\"> 0.303191</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20180122_155408_model_10           </td><td style=\"text-align: right;\">0.927598</td><td style=\"text-align: right;\"> 0.305166</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20180122_155408_model_19           </td><td style=\"text-align: right;\">0.924526</td><td style=\"text-align: right;\"> 0.30767 </td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20180122_155408_model_2            </td><td style=\"text-align: right;\">0.92362 </td><td style=\"text-align: right;\"> 0.309027</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20180122_155408_model_3            </td><td style=\"text-align: right;\">0.923346</td><td style=\"text-align: right;\"> 0.310539</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20180122_155408_model_0            </td><td style=\"text-align: right;\">0.920179</td><td style=\"text-align: right;\"> 0.315533</td></tr>\n",
       "<tr><td>XRT_0_AutoML_20180122_155408                         </td><td style=\"text-align: right;\">0.914966</td><td style=\"text-align: right;\"> 0.514152</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_0_AutoML_20180122_155408   </td><td style=\"text-align: right;\">0.913443</td><td style=\"text-align: right;\"> 0.3138  </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_0_AutoML_20180122_155408</td><td style=\"text-align: right;\">0.911898</td><td style=\"text-align: right;\"> 0.318742</td></tr>\n",
       "<tr><td>DRF_0_AutoML_20180122_155408                         </td><td style=\"text-align: right;\">0.911625</td><td style=\"text-align: right;\"> 0.685153</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generate Predictions..\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml = H2OAutoML(max_runtime_secs = 120)\n",
    "aml.train(x=x, y=y, training_frame=htrain)\n",
    "\n",
    "lb = aml.leaderboard\n",
    "print(lb)\n",
    "\n",
    "print('Generate Predictions..')\n",
    "\n",
    "test_y = aml.leader.predict(htest)\n",
    "test_y = test_y.as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the submission\n",
    "test_file = '/Users/hugo/Projects/Kaggle/Titanic-Kaggle/data/test.csv'\n",
    "test_data = pd.read_csv(test_file)\n",
    "test_Id = test_data['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"PassengerId\": test_Id, \"Survived\": test_y['predict']})\n",
    "df.to_csv(\"/Users/hugo/Projects/Kaggle/Titanic-Kaggle/output/submission-h2o.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
